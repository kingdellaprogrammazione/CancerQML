{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "from typing import Any\n",
    "\n",
    "import pennylane as qml\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "#device_gpu = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class VQC(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_wires: int,\n",
    "        num_outputs: int,\n",
    "        num_layers: int,\n",
    "        encoding: str = \"angle\",\n",
    "        reuploading: bool = False,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        @encoding: String which represents the gates used for the Angle encoding\n",
    "        @Ansatz: String which represents the ansatz used for quantum circuit\n",
    "        @Reuploading: Boolean indicating whether or not to use reuploading\n",
    "        @hadamard: Boolean indicating whether or not to use Hadamard gates\n",
    "        @num_layers: Integer representing the number of layers in the quantum circuit\n",
    "        @num_wires: Integer representing the number of wires in the quantum circuit\n",
    "        @num_outputs: Integer representing the number of output qubits\n",
    "        @gate_used: String representing the encoding gate used\n",
    "        @name_ansatz: String representing the ansatz used\n",
    "        \"\"\"\n",
    "        self.encoding = encoding\n",
    "        self.reuploading = reuploading\n",
    "        self.num_layers = num_layers\n",
    "        self.num_wires = num_wires\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        # PennyLane device\n",
    "        self.dev = qml.device(\"default.qubit\", wires=self.num_wires)\n",
    "        \n",
    "\n",
    "        # Set device for PyTorch\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.weight_shapes = {\"weights\": (self.num_layers, self.num_wires, 3)}\n",
    "        # Create the quantum node\n",
    "        self.qnode = self.create_qnode()\n",
    "        # Define the quantum layer in PyTorch\n",
    "        self.qlayer = qml.qnn.TorchLayer(self.qnode, self.weight_shapes).to(self.device)\n",
    "\n",
    "    def create_qnode(self) -> qml.QNode:\n",
    "        \"\"\"Creates the quantum node for the hybrid model.\"\"\"\n",
    "\n",
    "        @qml.qnode(self.dev)\n",
    "        def qnode(inputs: torch.Tensor, weights: torch.nn.parameter.Parameter) -> list[Any]:\n",
    "            # Encoding and Ansatz logic\n",
    "            if self.reuploading:\n",
    "                if self.encoding == \"angle\":\n",
    "                    for w in weights:\n",
    "                        self.encoding_circuit(inputs)\n",
    "                        self.apply_ansatz(w.unsqueeze(0))\n",
    "                elif self.encoding == \"amplitude\":\n",
    "                    msg = \"Amplitude encoding is not supported with re-uploading.\"\n",
    "                    raise ValueError(msg)\n",
    "            else:\n",
    "                self.encoding_circuit(inputs)\n",
    "                self.apply_ansatz(weights)\n",
    "\n",
    "            # Measurement\n",
    "            return [qml.expval(qml.PauliZ(wires=i)) for i in range(self.num_outputs)]\n",
    "\n",
    "        return qnode\n",
    "\n",
    "    def apply_ansatz(self, weights: torch.nn.parameter.Parameter) -> None:\n",
    "        qml.StronglyEntanglingLayers(weights, wires=range(self.num_wires))\n",
    "\n",
    "    def encoding_circuit(self, inputs: torch.Tensor) -> None:\n",
    "        \"\"\"\n",
    "        Apply encoding circuit based on the specified encoding method.\n",
    "        @ inputs: array of input values in range [-1, 1]\n",
    "        \"\"\"\n",
    "        if self.encoding == \"angle\":\n",
    "            qml.AngleEmbedding(math.pi / 2 * inputs, wires=range(self.num_wires), rotation='Y')\n",
    "        \n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the hybrid model.\"\"\"\n",
    "        return self.qlayer(inputs)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
    "# Initialize MinMaxScaler with a range of (-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Fit and transform the training data, then transform the test data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "\n",
    "# Convert the arrays into PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid.values, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "def evaluation(\n",
    "    model: nn.Module,\n",
    "    x: torch.Tensor,\n",
    "    y: torch.Tensor,\n",
    "    threshold_classification: float = 0.5\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate the model\n",
    "    @model: nn.Module, model to evaluate, MANDATORY\n",
    "    @x: torch.Tensor, data, MANDATORY\n",
    "    @y: torch.Tensor, labels, MANDATORY\n",
    "    @criterion: None|nn.Module, loss function\n",
    "    @threshold_classification: float, threshold for classification\n",
    "    @metrics: None|list[str], list of metrics to evaluate\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # function needed for VQC\n",
    "        y_pred = (1 - model(x)) / 2\n",
    "    print(classification_report(y, y_pred > threshold_classification))\n",
    "    print(confusion_matrix(y, y_pred > threshold_classification))    \n",
    "    \n",
    "import torch\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    x_train: torch.Tensor,\n",
    "    y_train: torch.Tensor,\n",
    "    x_valid: None | torch.Tensor = None,\n",
    "    y_valid: None | torch.Tensor = None,\n",
    "    optimizer: torch.optim.Optimizer = None,\n",
    "    criterion: None | nn.Module = None,\n",
    "    epochs: int = 100,\n",
    "    batch_size: int = 32,\n",
    "    lr = 0.01,\n",
    "    early_stopping: bool = True,\n",
    "    patience: int = 5,\n",
    "    threshold_classification: float = 0.5,\n",
    "    verbose: bool = True,\n",
    ") -> nn.Module:\n",
    "    # Initialize metrics and losses\n",
    "    if criterion is None:\n",
    "        criterion = nn.BCELoss() if model.num_outputs == 1 else nn.CrossEntropyLoss()\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "    min_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    best_model_state = model.state_dict()  # Track best model state\n",
    "\n",
    "    x_train_dataloader = torch.utils.data.DataLoader(\n",
    "        torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        loss_res = 0\n",
    "        for x_batch, y_batch in x_train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = (1 - model(x_batch)) / 2\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_res += loss.item()\n",
    "        loss_res /= len(x_train_dataloader)\n",
    "\n",
    "        if early_stopping and x_valid is not None and y_valid is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                y_pred_valid = (1 - model(x_valid)) / 2\n",
    "                loss_valid = criterion(y_pred_valid, y_valid)\n",
    "\n",
    "            if loss_valid < min_loss:\n",
    "                min_loss = loss_valid\n",
    "                patience_counter = 0\n",
    "                best_model_state = model.state_dict()  # Save best model state\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Early stopping condition\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                model.load_state_dict(best_model_state)  # Restore best model\n",
    "                break\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch + 1}/{epochs} - loss: {loss_res:.4f}\")\n",
    "            print(\"Train\")\n",
    "            evaluation(\n",
    "                model=model,\n",
    "                x=x_train,\n",
    "                y=y_train,\n",
    "                threshold_classification=threshold_classification\n",
    "            )\n",
    "            if x_valid is not None and y_valid is not None:\n",
    "                print(\"Validation\")\n",
    "                evaluation(\n",
    "                    model=model,\n",
    "                    x=x_valid,\n",
    "                    y=y_valid,\n",
    "                    threshold_classification=threshold_classification\n",
    "                )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 - loss: 0.6612\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.97      0.80       321\n",
      "         1.0       0.70      0.12      0.21       170\n",
      "\n",
      "    accuracy                           0.68       491\n",
      "   macro avg       0.69      0.55      0.50       491\n",
      "weighted avg       0.68      0.68      0.59       491\n",
      "\n",
      "[[312   9]\n",
      " [149  21]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.94      0.77        80\n",
      "         1.0       0.44      0.09      0.15        43\n",
      "\n",
      "    accuracy                           0.64       123\n",
      "   macro avg       0.55      0.52      0.46       123\n",
      "weighted avg       0.58      0.64      0.56       123\n",
      "\n",
      "[[75  5]\n",
      " [39  4]]\n",
      "Epoch 2/1000 - loss: 0.6246\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.99      0.81       321\n",
      "         1.0       0.90      0.11      0.20       170\n",
      "\n",
      "    accuracy                           0.69       491\n",
      "   macro avg       0.79      0.55      0.50       491\n",
      "weighted avg       0.76      0.69      0.60       491\n",
      "\n",
      "[[319   2]\n",
      " [151  19]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.96      0.79        80\n",
      "         1.0       0.62      0.12      0.20        43\n",
      "\n",
      "    accuracy                           0.67       123\n",
      "   macro avg       0.65      0.54      0.49       123\n",
      "weighted avg       0.65      0.67      0.58       123\n",
      "\n",
      "[[77  3]\n",
      " [38  5]]\n",
      "Epoch 3/1000 - loss: 0.6082\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.99      0.80       321\n",
      "         1.0       0.80      0.07      0.13       170\n",
      "\n",
      "    accuracy                           0.67       491\n",
      "   macro avg       0.73      0.53      0.46       491\n",
      "weighted avg       0.71      0.67      0.57       491\n",
      "\n",
      "[[318   3]\n",
      " [158  12]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.99      0.80        80\n",
      "         1.0       0.80      0.09      0.17        43\n",
      "\n",
      "    accuracy                           0.67       123\n",
      "   macro avg       0.73      0.54      0.48       123\n",
      "weighted avg       0.72      0.67      0.58       123\n",
      "\n",
      "[[79  1]\n",
      " [39  4]]\n",
      "Epoch 4/1000 - loss: 0.5965\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.99      0.81       321\n",
      "         1.0       0.88      0.12      0.22       170\n",
      "\n",
      "    accuracy                           0.69       491\n",
      "   macro avg       0.78      0.56      0.51       491\n",
      "weighted avg       0.75      0.69      0.60       491\n",
      "\n",
      "[[318   3]\n",
      " [149  21]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.99      0.81        80\n",
      "         1.0       0.86      0.14      0.24        43\n",
      "\n",
      "    accuracy                           0.69       123\n",
      "   macro avg       0.77      0.56      0.52       123\n",
      "weighted avg       0.74      0.69      0.61       123\n",
      "\n",
      "[[79  1]\n",
      " [37  6]]\n",
      "Epoch 5/1000 - loss: 0.5818\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.98      0.81       321\n",
      "         1.0       0.85      0.17      0.28       170\n",
      "\n",
      "    accuracy                           0.70       491\n",
      "   macro avg       0.77      0.58      0.55       491\n",
      "weighted avg       0.75      0.70      0.63       491\n",
      "\n",
      "[[316   5]\n",
      " [141  29]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.96      0.81        80\n",
      "         1.0       0.77      0.23      0.36        43\n",
      "\n",
      "    accuracy                           0.71       123\n",
      "   macro avg       0.73      0.60      0.58       123\n",
      "weighted avg       0.72      0.71      0.65       123\n",
      "\n",
      "[[77  3]\n",
      " [33 10]]\n",
      "Epoch 6/1000 - loss: 0.5696\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.98      0.81       321\n",
      "         1.0       0.84      0.19      0.31       170\n",
      "\n",
      "    accuracy                           0.71       491\n",
      "   macro avg       0.77      0.58      0.56       491\n",
      "weighted avg       0.75      0.71      0.64       491\n",
      "\n",
      "[[315   6]\n",
      " [138  32]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.96      0.82        80\n",
      "         1.0       0.80      0.28      0.41        43\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.76      0.62      0.62       123\n",
      "weighted avg       0.74      0.72      0.68       123\n",
      "\n",
      "[[77  3]\n",
      " [31 12]]\n",
      "Epoch 7/1000 - loss: 0.5681\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.98      0.82       321\n",
      "         1.0       0.86      0.22      0.35       170\n",
      "\n",
      "    accuracy                           0.72       491\n",
      "   macro avg       0.78      0.60      0.58       491\n",
      "weighted avg       0.76      0.72      0.66       491\n",
      "\n",
      "[[315   6]\n",
      " [133  37]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82        80\n",
      "         1.0       0.81      0.30      0.44        43\n",
      "\n",
      "    accuracy                           0.73       123\n",
      "   macro avg       0.77      0.63      0.63       123\n",
      "weighted avg       0.75      0.73      0.69       123\n",
      "\n",
      "[[77  3]\n",
      " [30 13]]\n",
      "Epoch 8/1000 - loss: 0.5589\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.98      0.82       321\n",
      "         1.0       0.85      0.24      0.37       170\n",
      "\n",
      "    accuracy                           0.72       491\n",
      "   macro avg       0.78      0.61      0.59       491\n",
      "weighted avg       0.76      0.72      0.66       491\n",
      "\n",
      "[[314   7]\n",
      " [130  40]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82        80\n",
      "         1.0       0.76      0.30      0.43        43\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.74      0.63      0.63       123\n",
      "weighted avg       0.73      0.72      0.68       123\n",
      "\n",
      "[[76  4]\n",
      " [30 13]]\n",
      "Epoch 9/1000 - loss: 0.5576\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.97      0.82       321\n",
      "         1.0       0.83      0.26      0.39       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.77      0.62      0.61       491\n",
      "weighted avg       0.75      0.73      0.67       491\n",
      "\n",
      "[[312   9]\n",
      " [126  44]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.94      0.82        80\n",
      "         1.0       0.74      0.33      0.45        43\n",
      "\n",
      "    accuracy                           0.72       123\n",
      "   macro avg       0.73      0.63      0.63       123\n",
      "weighted avg       0.73      0.72      0.69       123\n",
      "\n",
      "[[75  5]\n",
      " [29 14]]\n",
      "Epoch 10/1000 - loss: 0.5495\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82       321\n",
      "         1.0       0.82      0.29      0.43       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.77      0.63      0.63       491\n",
      "weighted avg       0.75      0.73      0.69       491\n",
      "\n",
      "[[310  11]\n",
      " [121  49]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.93      0.82        80\n",
      "         1.0       0.74      0.40      0.52        43\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.74      0.66      0.67       123\n",
      "weighted avg       0.74      0.74      0.71       123\n",
      "\n",
      "[[74  6]\n",
      " [26 17]]\n",
      "Epoch 11/1000 - loss: 0.5429\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82       321\n",
      "         1.0       0.81      0.28      0.41       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.76      0.62      0.62       491\n",
      "weighted avg       0.75      0.73      0.68       491\n",
      "\n",
      "[[310  11]\n",
      " [123  47]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.93      0.82        80\n",
      "         1.0       0.74      0.40      0.52        43\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.74      0.66      0.67       123\n",
      "weighted avg       0.74      0.74      0.71       123\n",
      "\n",
      "[[74  6]\n",
      " [26 17]]\n",
      "Epoch 12/1000 - loss: 0.5450\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.97      0.82       321\n",
      "         1.0       0.82      0.29      0.43       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.77      0.63      0.63       491\n",
      "weighted avg       0.75      0.73      0.69       491\n",
      "\n",
      "[[310  11]\n",
      " [121  49]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.93      0.82        80\n",
      "         1.0       0.74      0.40      0.52        43\n",
      "\n",
      "    accuracy                           0.74       123\n",
      "   macro avg       0.74      0.66      0.67       123\n",
      "weighted avg       0.74      0.74      0.71       123\n",
      "\n",
      "[[74  6]\n",
      " [26 17]]\n",
      "Epoch 13/1000 - loss: 0.5337\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.95      0.82       321\n",
      "         1.0       0.77      0.31      0.44       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.75      0.63      0.63       491\n",
      "weighted avg       0.74      0.73      0.69       491\n",
      "\n",
      "[[305  16]\n",
      " [117  53]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83        80\n",
      "         1.0       0.76      0.44      0.56        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.76      0.68      0.70       123\n",
      "weighted avg       0.76      0.76      0.74       123\n",
      "\n",
      "[[74  6]\n",
      " [24 19]]\n",
      "Epoch 14/1000 - loss: 0.5399\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82       321\n",
      "         1.0       0.78      0.29      0.43       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.75      0.63      0.62       491\n",
      "weighted avg       0.74      0.73      0.68       491\n",
      "\n",
      "[[307  14]\n",
      " [120  50]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83        80\n",
      "         1.0       0.75      0.42      0.54        43\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.75      0.67      0.68       123\n",
      "weighted avg       0.75      0.75      0.73       123\n",
      "\n",
      "[[74  6]\n",
      " [25 18]]\n",
      "Epoch 15/1000 - loss: 0.5326\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82       321\n",
      "         1.0       0.78      0.29      0.43       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.75      0.63      0.62       491\n",
      "weighted avg       0.74      0.73      0.68       491\n",
      "\n",
      "[[307  14]\n",
      " [120  50]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83        80\n",
      "         1.0       0.75      0.42      0.54        43\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.75      0.67      0.68       123\n",
      "weighted avg       0.75      0.75      0.73       123\n",
      "\n",
      "[[74  6]\n",
      " [25 18]]\n",
      "Epoch 16/1000 - loss: 0.5265\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82       321\n",
      "         1.0       0.79      0.31      0.45       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.76      0.63      0.64       491\n",
      "weighted avg       0.75      0.73      0.69       491\n",
      "\n",
      "[[307  14]\n",
      " [117  53]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83        80\n",
      "         1.0       0.76      0.44      0.56        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.76      0.68      0.70       123\n",
      "weighted avg       0.76      0.76      0.74       123\n",
      "\n",
      "[[74  6]\n",
      " [24 19]]\n",
      "Epoch 17/1000 - loss: 0.5308\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.96      0.82       321\n",
      "         1.0       0.80      0.31      0.44       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.76      0.63      0.63       491\n",
      "weighted avg       0.75      0.73      0.69       491\n",
      "\n",
      "[[308  13]\n",
      " [118  52]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83        80\n",
      "         1.0       0.75      0.42      0.54        43\n",
      "\n",
      "    accuracy                           0.75       123\n",
      "   macro avg       0.75      0.67      0.68       123\n",
      "weighted avg       0.75      0.75      0.73       123\n",
      "\n",
      "[[74  6]\n",
      " [25 18]]\n",
      "Epoch 18/1000 - loss: 0.5317\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83       321\n",
      "         1.0       0.81      0.32      0.46       170\n",
      "\n",
      "    accuracy                           0.74       491\n",
      "   macro avg       0.77      0.64      0.65       491\n",
      "weighted avg       0.76      0.74      0.70       491\n",
      "\n",
      "[[308  13]\n",
      " [115  55]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84        80\n",
      "         1.0       0.77      0.47      0.58        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.77      0.70      0.71       123\n",
      "weighted avg       0.77      0.76      0.75       123\n",
      "\n",
      "[[74  6]\n",
      " [23 20]]\n",
      "Epoch 19/1000 - loss: 0.5231\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.96      0.83       321\n",
      "         1.0       0.82      0.31      0.45       170\n",
      "\n",
      "    accuracy                           0.74       491\n",
      "   macro avg       0.77      0.64      0.64       491\n",
      "weighted avg       0.76      0.74      0.70       491\n",
      "\n",
      "[[309  12]\n",
      " [117  53]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84        80\n",
      "         1.0       0.77      0.47      0.58        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.77      0.70      0.71       123\n",
      "weighted avg       0.77      0.76      0.75       123\n",
      "\n",
      "[[74  6]\n",
      " [23 20]]\n",
      "Epoch 20/1000 - loss: 0.5210\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.94      0.82       321\n",
      "         1.0       0.76      0.33      0.46       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.74      0.64      0.64       491\n",
      "weighted avg       0.74      0.73      0.70       491\n",
      "\n",
      "[[303  18]\n",
      " [114  56]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 21/1000 - loss: 0.5204\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.94      0.82       321\n",
      "         1.0       0.76      0.34      0.47       170\n",
      "\n",
      "    accuracy                           0.73       491\n",
      "   macro avg       0.74      0.64      0.64       491\n",
      "weighted avg       0.74      0.73      0.70       491\n",
      "\n",
      "[[303  18]\n",
      " [113  57]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 22/1000 - loss: 0.5386\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.82       321\n",
      "         1.0       0.77      0.34      0.47       170\n",
      "\n",
      "    accuracy                           0.74       491\n",
      "   macro avg       0.75      0.64      0.65       491\n",
      "weighted avg       0.74      0.74      0.70       491\n",
      "\n",
      "[[304  17]\n",
      " [113  57]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 23/1000 - loss: 0.5170\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.95      0.83       321\n",
      "         1.0       0.78      0.35      0.49       170\n",
      "\n",
      "    accuracy                           0.74       491\n",
      "   macro avg       0.76      0.65      0.66       491\n",
      "weighted avg       0.75      0.74      0.71       491\n",
      "\n",
      "[[304  17]\n",
      " [110  60]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 24/1000 - loss: 0.5231\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.95      0.83       321\n",
      "         1.0       0.78      0.36      0.49       170\n",
      "\n",
      "    accuracy                           0.74       491\n",
      "   macro avg       0.76      0.65      0.66       491\n",
      "weighted avg       0.75      0.74      0.71       491\n",
      "\n",
      "[[304  17]\n",
      " [109  61]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 25/1000 - loss: 0.5191\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.95      0.83       321\n",
      "         1.0       0.80      0.35      0.49       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.77      0.65      0.66       491\n",
      "weighted avg       0.76      0.75      0.71       491\n",
      "\n",
      "[[306  15]\n",
      " [110  60]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 26/1000 - loss: 0.5129\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.94      0.83       321\n",
      "         1.0       0.78      0.37      0.50       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.76      0.66      0.67       491\n",
      "weighted avg       0.75      0.75      0.72       491\n",
      "\n",
      "[[303  18]\n",
      " [107  63]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 27/1000 - loss: 0.5138\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.94      0.83       321\n",
      "         1.0       0.78      0.37      0.50       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.76      0.66      0.67       491\n",
      "weighted avg       0.75      0.75      0.72       491\n",
      "\n",
      "[[303  18]\n",
      " [107  63]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 28/1000 - loss: 0.5198\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.93      0.83       321\n",
      "         1.0       0.75      0.39      0.52       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.66      0.67       491\n",
      "weighted avg       0.75      0.75      0.72       491\n",
      "\n",
      "[[299  22]\n",
      " [103  67]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 29/1000 - loss: 0.5246\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.93      0.83       321\n",
      "         1.0       0.75      0.39      0.52       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.66      0.67       491\n",
      "weighted avg       0.75      0.75      0.72       491\n",
      "\n",
      "[[299  22]\n",
      " [103  67]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 30/1000 - loss: 0.5215\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.93      0.83       321\n",
      "         1.0       0.76      0.39      0.51       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.66      0.67       491\n",
      "weighted avg       0.75      0.75      0.72       491\n",
      "\n",
      "[[300  21]\n",
      " [104  66]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.91      0.83        80\n",
      "         1.0       0.75      0.49      0.59        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.76      0.70      0.71       123\n",
      "weighted avg       0.76      0.76      0.75       123\n",
      "\n",
      "[[73  7]\n",
      " [22 21]]\n",
      "Epoch 31/1000 - loss: 0.5100\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.76      0.42      0.54       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.67      0.68       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[298  23]\n",
      " [ 99  71]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.91      0.83        80\n",
      "         1.0       0.75      0.49      0.59        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.76      0.70      0.71       123\n",
      "weighted avg       0.76      0.76      0.75       123\n",
      "\n",
      "[[73  7]\n",
      " [22 21]]\n",
      "Epoch 32/1000 - loss: 0.5128\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.93      0.83       321\n",
      "         1.0       0.76      0.39      0.52       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.66      0.67       491\n",
      "weighted avg       0.75      0.75      0.72       491\n",
      "\n",
      "[[300  21]\n",
      " [103  67]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.91      0.83        80\n",
      "         1.0       0.75      0.49      0.59        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.76      0.70      0.71       123\n",
      "weighted avg       0.76      0.76      0.75       123\n",
      "\n",
      "[[73  7]\n",
      " [22 21]]\n",
      "Epoch 33/1000 - loss: 0.5074\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.93      0.83       321\n",
      "         1.0       0.76      0.39      0.52       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.66      0.67       491\n",
      "weighted avg       0.75      0.75      0.72       491\n",
      "\n",
      "[[300  21]\n",
      " [103  67]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.91      0.83        80\n",
      "         1.0       0.75      0.49      0.59        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.76      0.70      0.71       123\n",
      "weighted avg       0.76      0.76      0.75       123\n",
      "\n",
      "[[73  7]\n",
      " [22 21]]\n",
      "Epoch 34/1000 - loss: 0.5085\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.94      0.83       321\n",
      "         1.0       0.79      0.39      0.53       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.77      0.67      0.68       491\n",
      "weighted avg       0.76      0.75      0.73       491\n",
      "\n",
      "[[303  18]\n",
      " [103  67]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.91      0.83        80\n",
      "         1.0       0.74      0.47      0.57        43\n",
      "\n",
      "    accuracy                           0.76       123\n",
      "   macro avg       0.75      0.69      0.70       123\n",
      "weighted avg       0.75      0.76      0.74       123\n",
      "\n",
      "[[73  7]\n",
      " [23 20]]\n",
      "Epoch 35/1000 - loss: 0.5043\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.94      0.83       321\n",
      "         1.0       0.78      0.39      0.52       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.76      0.67      0.68       491\n",
      "weighted avg       0.76      0.75      0.73       491\n",
      "\n",
      "[[302  19]\n",
      " [103  67]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 36/1000 - loss: 0.5025\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.76      0.41      0.53       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.67      0.68       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[299  22]\n",
      " [101  69]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 37/1000 - loss: 0.5088\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.76      0.40      0.53       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.76      0.67      0.68       491\n",
      "weighted avg       0.75      0.75      0.72       491\n",
      "\n",
      "[[300  21]\n",
      " [102  68]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 38/1000 - loss: 0.5064\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.76      0.41      0.53       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.67      0.68       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[299  22]\n",
      " [101  69]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 39/1000 - loss: 0.5082\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.76      0.41      0.53       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.76      0.67      0.68       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[299  22]\n",
      " [100  70]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 40/1000 - loss: 0.5146\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.75      0.41      0.53       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.67      0.68       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[298  23]\n",
      " [100  70]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 41/1000 - loss: 0.5052\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.91      0.82       321\n",
      "         1.0       0.72      0.43      0.54       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.74      0.67      0.68       491\n",
      "weighted avg       0.74      0.75      0.73       491\n",
      "\n",
      "[[293  28]\n",
      " [ 97  73]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 42/1000 - loss: 0.5100\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.76      0.42      0.54       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.67      0.68       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[298  23]\n",
      " [ 99  71]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 43/1000 - loss: 0.5082\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.92      0.83       321\n",
      "         1.0       0.74      0.43      0.54       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.74      0.67      0.69       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[295  26]\n",
      " [ 97  73]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 44/1000 - loss: 0.5088\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.76      0.40      0.52       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.67      0.68       491\n",
      "weighted avg       0.75      0.75      0.72       491\n",
      "\n",
      "[[299  22]\n",
      " [102  68]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 45/1000 - loss: 0.5085\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.75      0.42      0.54       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.67      0.69       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[297  24]\n",
      " [ 98  72]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 46/1000 - loss: 0.5085\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.44      0.55       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.69       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 47/1000 - loss: 0.5093\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 48/1000 - loss: 0.5055\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.44      0.55       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.69       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 49/1000 - loss: 0.5076\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.92      0.83       321\n",
      "         1.0       0.75      0.44      0.55       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.68      0.69       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[296  25]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 50/1000 - loss: 0.5032\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.77      0.42      0.55       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.69       491\n",
      "weighted avg       0.76      0.76      0.73       491\n",
      "\n",
      "[[299  22]\n",
      " [ 98  72]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 51/1000 - loss: 0.5024\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.75      0.42      0.54       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.67      0.69       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[297  24]\n",
      " [ 98  72]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 52/1000 - loss: 0.5066\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.77      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 53/1000 - loss: 0.5049\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.77      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[299  22]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 54/1000 - loss: 0.5068\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.92      0.83       321\n",
      "         1.0       0.74      0.44      0.55       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.68      0.69       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[295  26]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 55/1000 - loss: 0.5095\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.92      0.83       321\n",
      "         1.0       0.74      0.43      0.54       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.68      0.69       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[296  25]\n",
      " [ 97  73]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 56/1000 - loss: 0.4979\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.92      0.83       321\n",
      "         1.0       0.74      0.45      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.75      0.68      0.70       491\n",
      "weighted avg       0.75      0.76      0.74       491\n",
      "\n",
      "[[294  27]\n",
      " [ 93  77]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 57/1000 - loss: 0.5029\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.92      0.83       321\n",
      "         1.0       0.75      0.44      0.55       170\n",
      "\n",
      "    accuracy                           0.75       491\n",
      "   macro avg       0.75      0.68      0.69       491\n",
      "weighted avg       0.75      0.75      0.73       491\n",
      "\n",
      "[[296  25]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 58/1000 - loss: 0.5020\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.77      0.42      0.55       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.69       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[300  21]\n",
      " [ 98  72]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 59/1000 - loss: 0.5009\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.78      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.77      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[300  21]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 60/1000 - loss: 0.5040\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 61/1000 - loss: 0.4963\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.77      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 62/1000 - loss: 0.5026\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.78      0.43      0.55       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.77      0.68      0.69       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[300  21]\n",
      " [ 97  73]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 63/1000 - loss: 0.5079\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.93      0.83       321\n",
      "         1.0       0.76      0.43      0.55       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.69       491\n",
      "weighted avg       0.76      0.76      0.73       491\n",
      "\n",
      "[[298  23]\n",
      " [ 97  73]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 64/1000 - loss: 0.5034\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 65/1000 - loss: 0.5066\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.93      0.85        80\n",
      "         1.0       0.79      0.51      0.62        43\n",
      "\n",
      "    accuracy                           0.78       123\n",
      "   macro avg       0.78      0.72      0.73       123\n",
      "weighted avg       0.78      0.78      0.77       123\n",
      "\n",
      "[[74  6]\n",
      " [21 22]]\n",
      "Epoch 66/1000 - loss: 0.5022\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.77      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 67/1000 - loss: 0.5122\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.77      0.43      0.55       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.69       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[299  22]\n",
      " [ 97  73]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 68/1000 - loss: 0.5009\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.92      0.83       321\n",
      "         1.0       0.75      0.46      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[295  26]\n",
      " [ 92  78]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 69/1000 - loss: 0.5034\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.77      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 70/1000 - loss: 0.4985\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.77      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 71/1000 - loss: 0.4967\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.44      0.55       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.69       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 72/1000 - loss: 0.5039\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.76      0.45      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 93  77]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 73/1000 - loss: 0.5005\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.77      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[299  22]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 74/1000 - loss: 0.5047\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.93      0.84       321\n",
      "         1.0       0.77      0.46      0.58       170\n",
      "\n",
      "    accuracy                           0.77       491\n",
      "   macro avg       0.77      0.69      0.71       491\n",
      "weighted avg       0.77      0.77      0.75       491\n",
      "\n",
      "[[297  24]\n",
      " [ 91  79]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 75/1000 - loss: 0.5065\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.77      0.45      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.77      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 93  77]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 76/1000 - loss: 0.5038\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.76      0.45      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 93  77]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 77/1000 - loss: 0.4976\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.93      0.84       321\n",
      "         1.0       0.77      0.46      0.58       170\n",
      "\n",
      "    accuracy                           0.77       491\n",
      "   macro avg       0.77      0.69      0.71       491\n",
      "weighted avg       0.77      0.77      0.75       491\n",
      "\n",
      "[[297  24]\n",
      " [ 91  79]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 78/1000 - loss: 0.4943\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.76      0.46      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.71       491\n",
      "weighted avg       0.76      0.76      0.75       491\n",
      "\n",
      "[[297  24]\n",
      " [ 92  78]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 79/1000 - loss: 0.4943\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.45      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 94  76]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 80/1000 - loss: 0.5023\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.45      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 94  76]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 81/1000 - loss: 0.4988\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.76      0.45      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 93  77]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 82/1000 - loss: 0.4971\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.76      0.46      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.71       491\n",
      "weighted avg       0.76      0.76      0.75       491\n",
      "\n",
      "[[297  24]\n",
      " [ 92  78]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 83/1000 - loss: 0.4991\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.77      0.44      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 95  75]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 84/1000 - loss: 0.4965\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.45      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 94  76]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 85/1000 - loss: 0.4982\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.44      0.55       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.68      0.69       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[298  23]\n",
      " [ 96  74]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 86/1000 - loss: 0.4979\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.76      0.46      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.71       491\n",
      "weighted avg       0.76      0.76      0.75       491\n",
      "\n",
      "[[297  24]\n",
      " [ 92  78]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 87/1000 - loss: 0.4952\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.76      0.46      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.71       491\n",
      "weighted avg       0.76      0.76      0.75       491\n",
      "\n",
      "[[297  24]\n",
      " [ 92  78]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 88/1000 - loss: 0.5055\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.45      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 94  76]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 89/1000 - loss: 0.4941\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.93      0.84       321\n",
      "         1.0       0.77      0.46      0.58       170\n",
      "\n",
      "    accuracy                           0.77       491\n",
      "   macro avg       0.77      0.69      0.71       491\n",
      "weighted avg       0.77      0.77      0.75       491\n",
      "\n",
      "[[297  24]\n",
      " [ 91  79]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 90/1000 - loss: 0.4976\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.45      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 94  76]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Epoch 91/1000 - loss: 0.5036\n",
      "Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.83       321\n",
      "         1.0       0.76      0.45      0.56       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 94  76]]\n",
      "Validation\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n",
      "Early stopping at epoch 92\n"
     ]
    }
   ],
   "source": [
    "model = VQC(num_wires=8, num_outputs=1, num_layers=16, encoding=\"angle\", reuploading=False)\n",
    "model = train(model, X_train, y_train,X_valid, y_valid, epochs=1000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       321\n",
      "         1.0       0.76      0.45      0.57       170\n",
      "\n",
      "    accuracy                           0.76       491\n",
      "   macro avg       0.76      0.69      0.70       491\n",
      "weighted avg       0.76      0.76      0.74       491\n",
      "\n",
      "[[297  24]\n",
      " [ 93  77]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.91      0.84        80\n",
      "         1.0       0.76      0.51      0.61        43\n",
      "\n",
      "    accuracy                           0.77       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.77      0.77      0.76       123\n",
      "\n",
      "[[73  7]\n",
      " [21 22]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(model, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.85      0.80        99\n",
      "         1.0       0.66      0.53      0.59        55\n",
      "\n",
      "    accuracy                           0.73       154\n",
      "   macro avg       0.71      0.69      0.69       154\n",
      "weighted avg       0.73      0.73      0.73       154\n",
      "\n",
      "[[84 15]\n",
      " [26 29]]\n"
     ]
    }
   ],
   "source": [
    "evaluation(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
